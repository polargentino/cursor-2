'''
Acerca del desafÃ­o ğŸ’¡
DescripciÃ³n

Telecom X - AnÃ¡lisis de EvasiÃ³n de Clientes
Has sido contratado como asistente de anÃ¡lisis de datos en Telecom X y formarÃ¡s parte del proyecto "Churn de Clientes". La empresa enfrenta una alta tasa de cancelaciones y necesita comprender los factores que llevan a la pÃ©rdida de clientes.

Tu desafÃ­o serÃ¡ recopilar, procesar y analizar los datos, utilizando Python y sus principales bibliotecas para extraer informaciÃ³n valiosa. A partir de tu anÃ¡lisis, el equipo de Data Science podrÃ¡ avanzar en modelos predictivos y desarrollar estrategias para reducir la evasiÃ³n.

Â¿QuÃ© vas a practicar? âœ… Importar y manipular datos desde una API de manera eficiente. âœ… Aplicar los conceptos de ETL (ExtracciÃ³n, TransformaciÃ³n y Carga) en la preparaciÃ³n de los datos. âœ… Crear visualizaciones estratÃ©gicas para identificar patrones y tendencias. âœ… Realizar un AnÃ¡lisis Exploratorio de Datos (EDA) y generar un informe con insights relevantes.

Â¡Ahora es tu turno! ğŸš€ Usa tus conocimientos para transformar datos en informaciÃ³n estratÃ©gica y ayudar a Telecom X a retener mÃ¡s clientes.

1-ExtracciÃ³n de datos:
DescripciÃ³n Para iniciar tu anÃ¡lisis, necesitarÃ¡s importar los datos de la API de Telecom X. Estos datos estÃ¡n disponibles en formato JSON y contienen informaciÃ³n esencial sobre los clientes, incluyendo datos demogrÃ¡ficos, tipo de servicio contratado y estado de evasiÃ³n.

ğŸ“Œ Enlace de la API: ğŸ”— challenge2-data-science-LATAM/TelecomX_Data.json at main Â· ingridcristh/challenge2-data-science-LATAM

ğŸ”—GitHub - ingridcristh/challenge2-data-science-LATAM

Â¿QuÃ© debes hacer? âœ… Cargar los datos directamente desde la API utilizando Python. âœ… Convertir los datos a un DataFrame de Pandas para facilitar su manipulaciÃ³n.

Este es el primer paso para transformar los datos en informaciÃ³n valiosa. Â¿Listo para programar? ğŸš€

2 - Conoce el conjunto de datos
DescripciÃ³n Ahora que has extraÃ­do los datos, es fundamental comprender la estructura del dataset y el significado de sus columnas. Esta etapa te ayudarÃ¡ a identificar quÃ© variables son mÃ¡s relevantes para el anÃ¡lisis de evasiÃ³n de clientes.

ğŸ“Œ Para facilitar este proceso, hemos creado un diccionario de datos con la descripciÃ³n de cada columna. Aunque no es obligatorio utilizarlo, puede ayudarte a comprender mejor la informaciÃ³n disponible.

ğŸ”— Enlace al diccionario y a la API

Â¿QuÃ© debes hacer? âœ… Explorar las columnas del dataset y verificar sus tipos de datos. âœ… Consultar el diccionario para comprender mejor el significado de las variables. âœ… Identificar las columnas mÃ¡s relevantes para el anÃ¡lisis de evasiÃ³n.

ğŸ“Œ Tips: ğŸ”— DocumentaciÃ³n de DataFrame.info() ğŸ”— DocumentaciÃ³n de DataFrame.dtypes

3 - ComprobaciÃ³n de incoherencias en los datos
DescripciÃ³n En este paso, verifica si hay problemas en los datos que puedan afectar el anÃ¡lisis. Presta atenciÃ³n a valores ausentes, duplicados, errores de formato e inconsistencias en las categorÃ­as. Este proceso es esencial para asegurarte de que los datos estÃ©n listos para las siguientes etapas.

ğŸ“Œ Tips:

ğŸ”— DocumentaciÃ³n de pandas.unique() ğŸ”— DocumentaciÃ³n de pandas.Series.dt.normalize()

4 - Manejo de inconsistencias
DescripciÃ³n Ahora que has identificado las inconsistencias, es momento de aplicar las correcciones necesarias. Ajusta los datos para asegurarte de que estÃ©n completos y coherentes, preparÃ¡ndolos para las siguientes etapas del anÃ¡lisis.

ğŸ“Œ Tips:

ğŸ”— ManipulaciÃ³n de strings en pandas: lower, replace, startswith y contains | Alura Cursos Online

5 - Columna de cuentas diarias
DescripciÃ³n Ahora que los datos estÃ¡n limpios, es momento de crear la columna "Cuentas_Diarias". Utiliza la facturaciÃ³n mensual para calcular el valor diario, proporcionando una visiÃ³n mÃ¡s detallada del comportamiento de los clientes a lo largo del tiempo.

ğŸ“Œ Esta columna te ayudarÃ¡ a profundizar en el anÃ¡lisis y a obtener informaciÃ³n valiosa para las siguientes etapas.

6 - EstandarizaciÃ³n y transformaciÃ³n de datos (opcional)
DescripciÃ³n La estandarizaciÃ³n y transformaciÃ³n de datos es una etapa opcional, pero altamente recomendada, ya que busca hacer que la informaciÃ³n sea mÃ¡s consistente, comprensible y adecuada para el anÃ¡lisis. Durante esta fase, por ejemplo, puedes convertir valores textuales como "SÃ­" y "No" en valores binarios (1 y 0), lo que facilita el procesamiento matemÃ¡tico y la aplicaciÃ³n de modelos analÃ­ticos.

AdemÃ¡s, traducir o renombrar columnas y datos hace que la informaciÃ³n sea mÃ¡s accesible y fÃ¡cil de entender, especialmente cuando se trabaja con fuentes externas o tÃ©rminos tÃ©cnicos. Aunque no es un paso obligatorio, puede mejorar significativamente la claridad y comunicaciÃ³n de los resultados, facilitando la interpretaciÃ³n y evitando confusiones, especialmente al compartir informaciÃ³n con stakeholders no tÃ©cnicos.

7 - Carga y anÃ¡lisis(L - Load & Analysis)
AnÃ¡lisis Descriptivo
DescripciÃ³n Para comenzar, realiza un anÃ¡lisis descriptivo de los datos, calculando mÃ©tricas como media, mediana, desviaciÃ³n estÃ¡ndar y otras medidas que ayuden a comprender mejor la distribuciÃ³n y el comportamiento de los clientes.

ğŸ“Œ Consejos:

ğŸ”— DocumentaciÃ³n de DataFrame.describe()

8 - DistribuciÃ³n de evasiÃ³n
DescripciÃ³n En este paso, el objetivo es comprender cÃ³mo estÃ¡ distribuida la variable "churn" (evasiÃ³n) entre los clientes. Utiliza grÃ¡ficos para visualizar la proporciÃ³n de clientes que permanecieron y los que se dieron de baja.

9 - Recuento de evasiÃ³n por variables categÃ³ricas
DescripciÃ³n Ahora, exploraremos cÃ³mo se distribuye la evasiÃ³n segÃºn variables categÃ³ricas, como gÃ©nero, tipo de contrato, mÃ©todo de pago, entre otras.

Este anÃ¡lisis puede revelar patrones interesantes, por ejemplo, si los clientes de ciertos perfiles tienen una mayor tendencia a cancelar el servicio, lo que ayudarÃ¡ a orientar acciones estratÃ©gicas.

10 - Conteo de evasiÃ³n por variables numÃ©ricas
DescripciÃ³n En este paso, explora cÃ³mo las variables numÃ©ricas, como "total gastado" o "tiempo de contrato", se distribuyen entre los clientes que cancelaron (evasiÃ³n) y los que no cancelaron.

Este anÃ¡lisis ayuda a entender si ciertos valores numÃ©ricos estÃ¡n mÃ¡s asociados con la evasiÃ³n, proporcionando insights sobre los factores que influyen en el comportamiento de los clientes.

11 - Informe final
DescripciÃ³n Finaliza el desafÃ­o elaborando un informe dentro del mismo notebook que resuma todo el trabajo realizado. El informe debe incluir:

ğŸ”¹ IntroducciÃ³n: Explica el objetivo del anÃ¡lisis y el problema de evasiÃ³n de clientes (Churn).

ğŸ”¹ Limpieza y Tratamiento de Datos: Describe los pasos realizados para importar, limpiar y procesar los datos.

ğŸ”¹ AnÃ¡lisis Exploratorio de Datos: Presenta los anÃ¡lisis realizados, incluyendo grÃ¡ficos y visualizaciones para identificar patrones.

ğŸ”¹ Conclusiones e Insights: Resume los principales hallazgos y cÃ³mo estos datos pueden ayudar a reducir la evasiÃ³n.

ğŸ”¹ Recomendaciones: Ofrece sugerencias estratÃ©gicas basadas en tu anÃ¡lisis.

AsegÃºrate de que el informe estÃ© bien estructurado, claro y respaldado por visualizaciones que refuercen tus conclusiones. ğŸš€

12 - Â¡Extra! AnÃ¡lisis de correlaciÃ³n entre variables
DescripciÃ³n Esta actividad es un extra, por lo tanto es OPCIONAL.

Como un paso adicional, puedes explorar la correlaciÃ³n entre diferentes variables del dataset. Esto puede ayudar a identificar quÃ© factores tienen mayor relaciÃ³n con la evasiÃ³n de clientes, como:

ğŸ”¹ La relaciÃ³n entre la cuenta diaria y la evasiÃ³n. ğŸ”¹ CÃ³mo la cantidad de servicios contratados afecta la probabilidad de churn.

Puedes usar la funciÃ³n corr() de Pandas para calcular las correlaciones y visualizar los resultados con grÃ¡ficos de dispersiÃ³n o matrices de correlaciÃ³n.

Este anÃ¡lisis adicional puede proporcionar insights valiosos para la creaciÃ³n de modelos predictivos mÃ¡s robustos. ğŸš€
'''

import pandas as pd
import requests
import io

# Paso 1: ExtracciÃ³n de datos
# URL del archivo JSON en GitHub (raw)
url = "https://raw.githubusercontent.com/ingridcristh/challenge2-data-science-LATAM/main/TelecomX_Data.json"

# Descargar el contenido del archivo JSON
response = requests.get(url)
response.raise_for_status()  # Asegura que la descarga fue exitosa

# Cargar los datos en un DataFrame de pandas
data = pd.read_json(io.StringIO(response.text))

# Mostrar las primeras filas para verificar la carga
print("Primeras filas del DataFrame:")
print(data.head())

# Paso 2: Conocer el conjunto de datos
print("\nInformaciÃ³n general del DataFrame:")
data.info()

print("\nTipos de datos por columna:")
print(data.dtypes)

print("\nColumnas del DataFrame:")
print(data.columns.tolist())

'''
Primeras filas del DataFrame:
   customerID  ...                                            account
0  0002-ORFBO  ...  {'Contract': 'One year', 'PaperlessBilling': '...
1  0003-MKNFE  ...  {'Contract': 'Month-to-month', 'PaperlessBilli...
2  0004-TLHLJ  ...  {'Contract': 'Month-to-month', 'PaperlessBilli...
3  0011-IGKFF  ...  {'Contract': 'Month-to-month', 'PaperlessBilli...
4  0013-EXCHZ  ...  {'Contract': 'Month-to-month', 'PaperlessBilli...

[5 rows x 6 columns]

InformaciÃ³n general del DataFrame:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7267 entries, 0 to 7266
Data columns (total 6 columns):
 #   Column      Non-Null Count  Dtype 
---  ------      --------------  ----- 
 0   customerID  7267 non-null   object
 1   Churn       7267 non-null   object
 2   customer    7267 non-null   object
 3   phone       7267 non-null   object
 4   internet    7267 non-null   object
 5   account     7267 non-null   object
dtypes: object(6)
memory usage: 340.8+ KB

Tipos de datos por columna:
customerID    object
Churn         object
customer      object
phone         object
internet      object
account       object
dtype: object




Â¡Perfecto! Tienes un roadmap claro para abordar el desafÃ­o de anÃ¡lisis de churn en Telecom X. AquÃ­ tienes una guÃ­a paso a paso para avanzar, con sugerencias de cÃ³digo y enfoques para cada etapa:

1. ExtracciÃ³n de datos
Ya lo tienes hecho: descargaste y cargaste el JSON en un DataFrame.

2. Conoce el conjunto de datos
Ya mostraste las columnas y tipos de datos.
Siguiente paso: Explora el contenido de las columnas anidadas (customer, phone, internet, account), ya que parecen ser diccionarios.

'''
# Ejemplo: ver el contenido de la columna 'customer' en la primera fila
print(data['customer'][0])

'''
Columnas del DataFrame:
['customerID', 'Churn', 'customer', 'phone', 'internet', 'account']
{'gender': 'Female', 'SeniorCitizen': 0, 'Partner': 'Yes', 'Dependents': 'Yes', 'tenure': 9}
'''

'''
3. ComprobaciÃ³n de incoherencias en los datos
Busca valores nulos, duplicados y categorÃ­as extraÃ±as.
'''
# Expandir la columna 'account' en columnas separadas
account_df = pd.json_normalize(data['account'])
# Unir al DataFrame original
data = pd.concat([data.drop('account', axis=1), account_df], axis=1)

for col in ['customer', 'phone', 'internet']:
    expanded = pd.json_normalize(data[col])
    expanded.columns = [f"{col}_{subcol}" for subcol in expanded.columns]
    data = pd.concat([data.drop(col, axis=1), expanded], axis=1)
'''

'''
print(data.isnull().sum())  # Valores nulos por columna
print(data.duplicated().sum())  # Filas duplicadas



# Ejemplo para ver valores Ãºnicos en 'Churn'
print(data['Churn'].unique())

'''
customerID                   0
Churn                        0
Contract                     0
PaperlessBilling             0
PaymentMethod                0
Charges.Monthly              0
Charges.Total                0
customer_gender              0
customer_SeniorCitizen       0
customer_Partner             0
customer_Dependents          0
customer_tenure              0
phone_PhoneService           0
phone_MultipleLines          0
internet_InternetService     0
internet_OnlineSecurity      0
internet_OnlineBackup        0
internet_DeviceProtection    0
internet_TechSupport         0
internet_StreamingTV         0
internet_StreamingMovies     0
dtype: int64
0
['No' 'Yes' '']
'''
'''
Â¡Perfecto! Ya tienes el diagnÃ³stico: tus columnas anidadas (customer, phone, internet, account) contienen diccionarios, y ya has visto un ejemplo de su contenido.
Siguiente paso: Desanidar todas las columnas de diccionarios
Esto te permitirÃ¡:
Analizar fÃ¡cilmente los valores Ãºnicos, nulos, duplicados, etc.
Trabajar con un DataFrame "plano" y listo para anÃ¡lisis y visualizaciÃ³n.
CÃ³digo recomendado para desanidar todas las columnas anidadas
Agrega esto despuÃ©s de cargar el DataFrame y antes de cualquier anÃ¡lisis:


'''
cols_to_expand = ['customer', 'phone', 'internet', 'account']

for col in cols_to_expand:
    if col in data.columns:
        expanded = pd.json_normalize(data[col])
        expanded.columns = [f"{col}_{subcol}" for subcol in expanded.columns]
        data = pd.concat([data.drop(col, axis=1), expanded], axis=1)

'''
Â¡Genial! Ya tienes tu DataFrame completamente desanidado y plano, con columnas limpias y listas para el anÃ¡lisis. AquÃ­ tienes los siguientes pasos recomendados para avanzar en el desafÃ­o:
1. RevisiÃ³n de valores nulos, duplicados y categorÃ­as
Ya lo hiciste, pero asegÃºrate de revisar las nuevas columnas expandidas. Si todo estÃ¡ en orden (como parece por tu salida), Â¡puedes avanzar!
2. Limpieza y estandarizaciÃ³n de datos
Estandariza los valores de las columnas categÃ³ricas (por ejemplo, "Yes"/"No" a 1/0).
Reemplaza valores vacÃ­os o inconsistentes (por ejemplo, si hay valores '' en vez de NaN).
Ejemplo:
'''
# Estandarizar columnas Yes/No
yes_no_cols = [col for col in data.columns if data[col].isin(['Yes', 'No']).all()]
for col in yes_no_cols:
    data[col] = data[col].map({'Yes': 1, 'No': 0})

# Reemplazar strings vacÃ­os por NaN
import numpy as np
data.replace('', np.nan, inplace=True)

'''
3. Crear columna de cuentas diarias
Si tienes la columna Charges.Monthly, crea la columna Cuentas_Diarias:

'''
data['Cuentas_Diarias'] = data['Charges.Monthly'] / 30

'''
4. AnÃ¡lisis descriptivo
Usa describe() para ver estadÃ­sticas de las columnas numÃ©ricas.
Usa value_counts() para ver la distribuciÃ³n de las categÃ³ricas.
5. VisualizaciÃ³n de la evasiÃ³n (Churn)
Haz un grÃ¡fico de torta o barras para la variable Churn.
Ejemplo:
'''

import matplotlib.pyplot as plt
data['Churn'].value_counts().plot(kind='bar')
plt.title('DistribuciÃ³n de EvasiÃ³n (Churn)')
plt.show()

'''
6. AnÃ¡lisis de churn por variables relevantes
Usa tablas cruzadas y grÃ¡ficos para ver cÃ³mo se distribuye el churn segÃºn gÃ©nero, tipo de contrato, mÃ©todo de pago, etc.
Ejemplo
'''

pd.crosstab(data['Churn'], data['Contract']).plot(kind='bar', stacked=True)
plt.title('Churn por tipo de contrato')
plt.show()
'''
7. AnÃ¡lisis de churn por variables numÃ©ricas
Compara medias, medianas, etc., de Charges.Total, Cuentas_Diarias, tenure, etc., entre clientes que se fueron y los que no.
8. (Opcional) AnÃ¡lisis de correlaciÃ³n
Usa data.corr() y un heatmap para ver correlaciones entre variables numÃ©ricas y el churn.
9. Informe final
Estructura tu notebook/script con:
IntroducciÃ³n
Limpieza y tratamiento
AnÃ¡lisis exploratorio (con visualizaciones)
Conclusiones e insights
Recomendaciones
'''
