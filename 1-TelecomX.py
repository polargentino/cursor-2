'''
Acerca del desaf√≠o üí°
Descripci√≥n

Telecom X - An√°lisis de Evasi√≥n de Clientes
Has sido contratado como asistente de an√°lisis de datos en Telecom X y formar√°s parte del proyecto "Churn de Clientes". La empresa enfrenta una alta tasa de cancelaciones y necesita comprender los factores que llevan a la p√©rdida de clientes.

Tu desaf√≠o ser√° recopilar, procesar y analizar los datos, utilizando Python y sus principales bibliotecas para extraer informaci√≥n valiosa. A partir de tu an√°lisis, el equipo de Data Science podr√° avanzar en modelos predictivos y desarrollar estrategias para reducir la evasi√≥n.

¬øQu√© vas a practicar? ‚úÖ Importar y manipular datos desde una API de manera eficiente. ‚úÖ Aplicar los conceptos de ETL (Extracci√≥n, Transformaci√≥n y Carga) en la preparaci√≥n de los datos. ‚úÖ Crear visualizaciones estrat√©gicas para identificar patrones y tendencias. ‚úÖ Realizar un An√°lisis Exploratorio de Datos (EDA) y generar un informe con insights relevantes.

¬°Ahora es tu turno! üöÄ Usa tus conocimientos para transformar datos en informaci√≥n estrat√©gica y ayudar a Telecom X a retener m√°s clientes.

1-Extracci√≥n de datos:
Descripci√≥n Para iniciar tu an√°lisis, necesitar√°s importar los datos de la API de Telecom X. Estos datos est√°n disponibles en formato JSON y contienen informaci√≥n esencial sobre los clientes, incluyendo datos demogr√°ficos, tipo de servicio contratado y estado de evasi√≥n.

üìå Enlace de la API: üîó challenge2-data-science-LATAM/TelecomX_Data.json at main ¬∑ ingridcristh/challenge2-data-science-LATAM

üîóGitHub - ingridcristh/challenge2-data-science-LATAM

¬øQu√© debes hacer? ‚úÖ Cargar los datos directamente desde la API utilizando Python. ‚úÖ Convertir los datos a un DataFrame de Pandas para facilitar su manipulaci√≥n.

Este es el primer paso para transformar los datos en informaci√≥n valiosa. ¬øListo para programar? üöÄ

2 - Conoce el conjunto de datos
Descripci√≥n Ahora que has extra√≠do los datos, es fundamental comprender la estructura del dataset y el significado de sus columnas. Esta etapa te ayudar√° a identificar qu√© variables son m√°s relevantes para el an√°lisis de evasi√≥n de clientes.

üìå Para facilitar este proceso, hemos creado un diccionario de datos con la descripci√≥n de cada columna. Aunque no es obligatorio utilizarlo, puede ayudarte a comprender mejor la informaci√≥n disponible.

üîó Enlace al diccionario y a la API

¬øQu√© debes hacer? ‚úÖ Explorar las columnas del dataset y verificar sus tipos de datos. ‚úÖ Consultar el diccionario para comprender mejor el significado de las variables. ‚úÖ Identificar las columnas m√°s relevantes para el an√°lisis de evasi√≥n.

üìå Tips: üîó Documentaci√≥n de DataFrame.info() üîó Documentaci√≥n de DataFrame.dtypes

3 - Comprobaci√≥n de incoherencias en los datos
Descripci√≥n En este paso, verifica si hay problemas en los datos que puedan afectar el an√°lisis. Presta atenci√≥n a valores ausentes, duplicados, errores de formato e inconsistencias en las categor√≠as. Este proceso es esencial para asegurarte de que los datos est√©n listos para las siguientes etapas.

üìå Tips:

üîó Documentaci√≥n de pandas.unique() üîó Documentaci√≥n de pandas.Series.dt.normalize()

4 - Manejo de inconsistencias
Descripci√≥n Ahora que has identificado las inconsistencias, es momento de aplicar las correcciones necesarias. Ajusta los datos para asegurarte de que est√©n completos y coherentes, prepar√°ndolos para las siguientes etapas del an√°lisis.

üìå Tips:

üîó Manipulaci√≥n de strings en pandas: lower, replace, startswith y contains | Alura Cursos Online

5 - Columna de cuentas diarias
Descripci√≥n Ahora que los datos est√°n limpios, es momento de crear la columna "Cuentas_Diarias". Utiliza la facturaci√≥n mensual para calcular el valor diario, proporcionando una visi√≥n m√°s detallada del comportamiento de los clientes a lo largo del tiempo.

üìå Esta columna te ayudar√° a profundizar en el an√°lisis y a obtener informaci√≥n valiosa para las siguientes etapas.

6 - Estandarizaci√≥n y transformaci√≥n de datos (opcional)
Descripci√≥n La estandarizaci√≥n y transformaci√≥n de datos es una etapa opcional, pero altamente recomendada, ya que busca hacer que la informaci√≥n sea m√°s consistente, comprensible y adecuada para el an√°lisis. Durante esta fase, por ejemplo, puedes convertir valores textuales como "S√≠" y "No" en valores binarios (1 y 0), lo que facilita el procesamiento matem√°tico y la aplicaci√≥n de modelos anal√≠ticos.

Adem√°s, traducir o renombrar columnas y datos hace que la informaci√≥n sea m√°s accesible y f√°cil de entender, especialmente cuando se trabaja con fuentes externas o t√©rminos t√©cnicos. Aunque no es un paso obligatorio, puede mejorar significativamente la claridad y comunicaci√≥n de los resultados, facilitando la interpretaci√≥n y evitando confusiones, especialmente al compartir informaci√≥n con stakeholders no t√©cnicos.

7 - Carga y an√°lisis(L - Load & Analysis)
An√°lisis Descriptivo
Descripci√≥n Para comenzar, realiza un an√°lisis descriptivo de los datos, calculando m√©tricas como media, mediana, desviaci√≥n est√°ndar y otras medidas que ayuden a comprender mejor la distribuci√≥n y el comportamiento de los clientes.

üìå Consejos:

üîó Documentaci√≥n de DataFrame.describe()

8 - Distribuci√≥n de evasi√≥n
Descripci√≥n En este paso, el objetivo es comprender c√≥mo est√° distribuida la variable "churn" (evasi√≥n) entre los clientes. Utiliza gr√°ficos para visualizar la proporci√≥n de clientes que permanecieron y los que se dieron de baja.

9 - Recuento de evasi√≥n por variables categ√≥ricas
Descripci√≥n Ahora, exploraremos c√≥mo se distribuye la evasi√≥n seg√∫n variables categ√≥ricas, como g√©nero, tipo de contrato, m√©todo de pago, entre otras.

Este an√°lisis puede revelar patrones interesantes, por ejemplo, si los clientes de ciertos perfiles tienen una mayor tendencia a cancelar el servicio, lo que ayudar√° a orientar acciones estrat√©gicas.

10 - Conteo de evasi√≥n por variables num√©ricas
Descripci√≥n En este paso, explora c√≥mo las variables num√©ricas, como "total gastado" o "tiempo de contrato", se distribuyen entre los clientes que cancelaron (evasi√≥n) y los que no cancelaron.

Este an√°lisis ayuda a entender si ciertos valores num√©ricos est√°n m√°s asociados con la evasi√≥n, proporcionando insights sobre los factores que influyen en el comportamiento de los clientes.

11 - Informe final
Descripci√≥n Finaliza el desaf√≠o elaborando un informe dentro del mismo notebook que resuma todo el trabajo realizado. El informe debe incluir:

üîπ Introducci√≥n: Explica el objetivo del an√°lisis y el problema de evasi√≥n de clientes (Churn).

üîπ Limpieza y Tratamiento de Datos: Describe los pasos realizados para importar, limpiar y procesar los datos.

üîπ An√°lisis Exploratorio de Datos: Presenta los an√°lisis realizados, incluyendo gr√°ficos y visualizaciones para identificar patrones.

üîπ Conclusiones e Insights: Resume los principales hallazgos y c√≥mo estos datos pueden ayudar a reducir la evasi√≥n.

üîπ Recomendaciones: Ofrece sugerencias estrat√©gicas basadas en tu an√°lisis.

Aseg√∫rate de que el informe est√© bien estructurado, claro y respaldado por visualizaciones que refuercen tus conclusiones. üöÄ

12 - ¬°Extra! An√°lisis de correlaci√≥n entre variables
Descripci√≥n Esta actividad es un extra, por lo tanto es OPCIONAL.

Como un paso adicional, puedes explorar la correlaci√≥n entre diferentes variables del dataset. Esto puede ayudar a identificar qu√© factores tienen mayor relaci√≥n con la evasi√≥n de clientes, como:

üîπ La relaci√≥n entre la cuenta diaria y la evasi√≥n. üîπ C√≥mo la cantidad de servicios contratados afecta la probabilidad de churn.

Puedes usar la funci√≥n corr() de Pandas para calcular las correlaciones y visualizar los resultados con gr√°ficos de dispersi√≥n o matrices de correlaci√≥n.

Este an√°lisis adicional puede proporcionar insights valiosos para la creaci√≥n de modelos predictivos m√°s robustos. üöÄ
'''

import pandas as pd
import requests
import io

# Paso 1: Extracci√≥n de datos
# URL del archivo JSON en GitHub (raw)
url = "https://raw.githubusercontent.com/ingridcristh/challenge2-data-science-LATAM/main/TelecomX_Data.json"

# Descargar el contenido del archivo JSON
response = requests.get(url)
response.raise_for_status()  # Asegura que la descarga fue exitosa

# Cargar los datos en un DataFrame de pandas
data = pd.read_json(io.StringIO(response.text))

# Mostrar las primeras filas para verificar la carga
print("Primeras filas del DataFrame:")
print(data.head())

# Paso 2: Conocer el conjunto de datos
print("\nInformaci√≥n general del DataFrame:")
data.info()

print("\nTipos de datos por columna:")
print(data.dtypes)

print("\nColumnas del DataFrame:")
print(data.columns.tolist())

'''
Primeras filas del DataFrame:
   customerID  ...                                            account
0  0002-ORFBO  ...  {'Contract': 'One year', 'PaperlessBilling': '...
1  0003-MKNFE  ...  {'Contract': 'Month-to-month', 'PaperlessBilli...
2  0004-TLHLJ  ...  {'Contract': 'Month-to-month', 'PaperlessBilli...
3  0011-IGKFF  ...  {'Contract': 'Month-to-month', 'PaperlessBilli...
4  0013-EXCHZ  ...  {'Contract': 'Month-to-month', 'PaperlessBilli...

[5 rows x 6 columns]

Informaci√≥n general del DataFrame:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 7267 entries, 0 to 7266
Data columns (total 6 columns):
 #   Column      Non-Null Count  Dtype 
---  ------      --------------  ----- 
 0   customerID  7267 non-null   object
 1   Churn       7267 non-null   object
 2   customer    7267 non-null   object
 3   phone       7267 non-null   object
 4   internet    7267 non-null   object
 5   account     7267 non-null   object
dtypes: object(6)
memory usage: 340.8+ KB

Tipos de datos por columna:
customerID    object
Churn         object
customer      object
phone         object
internet      object
account       object
dtype: object




¬°Perfecto! Tienes un roadmap claro para abordar el desaf√≠o de an√°lisis de churn en Telecom X. Aqu√≠ tienes una gu√≠a paso a paso para avanzar, con sugerencias de c√≥digo y enfoques para cada etapa:

1. Extracci√≥n de datos
Ya lo tienes hecho: descargaste y cargaste el JSON en un DataFrame.

2. Conoce el conjunto de datos
Ya mostraste las columnas y tipos de datos.
Siguiente paso: Explora el contenido de las columnas anidadas (customer, phone, internet, account), ya que parecen ser diccionarios.

'''
# Ejemplo: ver el contenido de la columna 'customer' en la primera fila
print(data['customer'][0])

'''
Columnas del DataFrame:
['customerID', 'Churn', 'customer', 'phone', 'internet', 'account']
{'gender': 'Female', 'SeniorCitizen': 0, 'Partner': 'Yes', 'Dependents': 'Yes', 'tenure': 9}
'''

'''
3. Comprobaci√≥n de incoherencias en los datos
Busca valores nulos, duplicados y categor√≠as extra√±as.
'''
# Expandir la columna 'account' en columnas separadas
account_df = pd.json_normalize(data['account'])
# Unir al DataFrame original
data = pd.concat([data.drop('account', axis=1), account_df], axis=1)

for col in ['customer', 'phone', 'internet']:
    expanded = pd.json_normalize(data[col])
    expanded.columns = [f"{col}_{subcol}" for subcol in expanded.columns]
    data = pd.concat([data.drop(col, axis=1), expanded], axis=1)
'''

'''
print(data.isnull().sum())  # Valores nulos por columna
print(data.duplicated().sum())  # Filas duplicadas



# Ejemplo para ver valores √∫nicos en 'Churn'
print(data['Churn'].unique())

'''
customerID                   0
Churn                        0
Contract                     0
PaperlessBilling             0
PaymentMethod                0
Charges.Monthly              0
Charges.Total                0
customer_gender              0
customer_SeniorCitizen       0
customer_Partner             0
customer_Dependents          0
customer_tenure              0
phone_PhoneService           0
phone_MultipleLines          0
internet_InternetService     0
internet_OnlineSecurity      0
internet_OnlineBackup        0
internet_DeviceProtection    0
internet_TechSupport         0
internet_StreamingTV         0
internet_StreamingMovies     0
dtype: int64
0
['No' 'Yes' '']
'''
'''
¬°Perfecto! Ya tienes el diagn√≥stico: tus columnas anidadas (customer, phone, internet, account) contienen diccionarios, y ya has visto un ejemplo de su contenido.
Siguiente paso: Desanidar todas las columnas de diccionarios
Esto te permitir√°:
Analizar f√°cilmente los valores √∫nicos, nulos, duplicados, etc.
Trabajar con un DataFrame "plano" y listo para an√°lisis y visualizaci√≥n.
C√≥digo recomendado para desanidar todas las columnas anidadas
Agrega esto despu√©s de cargar el DataFrame y antes de cualquier an√°lisis:


'''
cols_to_expand = ['customer', 'phone', 'internet', 'account']

for col in cols_to_expand:
    if col in data.columns:
        expanded = pd.json_normalize(data[col])
        expanded.columns = [f"{col}_{subcol}" for subcol in expanded.columns]
        data = pd.concat([data.drop(col, axis=1), expanded], axis=1)

'''
¬°Genial! Ya tienes tu DataFrame completamente desanidado y plano, con columnas limpias y listas para el an√°lisis. Aqu√≠ tienes los siguientes pasos recomendados para avanzar en el desaf√≠o:
1. Revisi√≥n de valores nulos, duplicados y categor√≠as
Ya lo hiciste, pero aseg√∫rate de revisar las nuevas columnas expandidas. Si todo est√° en orden (como parece por tu salida), ¬°puedes avanzar!
2. Limpieza y estandarizaci√≥n de datos
Estandariza los valores de las columnas categ√≥ricas (por ejemplo, "Yes"/"No" a 1/0).
Reemplaza valores vac√≠os o inconsistentes (por ejemplo, si hay valores '' en vez de NaN).
Ejemplo:
'''
# Estandarizar columnas Yes/No
yes_no_cols = [col for col in data.columns if data[col].isin(['Yes', 'No']).all()]
for col in yes_no_cols:
    data[col] = data[col].map({'Yes': 1, 'No': 0})

# Reemplazar strings vac√≠os por NaN
import numpy as np
data.replace('', np.nan, inplace=True)

'''
3. Crear columna de cuentas diarias
Si tienes la columna Charges.Monthly, crea la columna Cuentas_Diarias:

'''
data['Cuentas_Diarias'] = data['Charges.Monthly'] / 30

'''
4. An√°lisis descriptivo
Usa describe() para ver estad√≠sticas de las columnas num√©ricas.
Usa value_counts() para ver la distribuci√≥n de las categ√≥ricas.
5. Visualizaci√≥n de la evasi√≥n (Churn)
Haz un gr√°fico de torta o barras para la variable Churn.
Ejemplo:
'''

import matplotlib.pyplot as plt
data['Churn'].value_counts().plot(kind='bar')
plt.title('Distribuci√≥n de Evasi√≥n (Churn)')
plt.show()

'''
6. An√°lisis de churn por variables relevantes
Usa tablas cruzadas y gr√°ficos para ver c√≥mo se distribuye el churn seg√∫n g√©nero, tipo de contrato, m√©todo de pago, etc.
Ejemplo
'''

pd.crosstab(data['Churn'], data['Contract']).plot(kind='bar', stacked=True)
plt.title('Churn por tipo de contrato')
plt.show()
'''
7. An√°lisis de churn por variables num√©ricas
Compara medias, medianas, etc., de Charges.Total, Cuentas_Diarias, tenure, etc., entre clientes que se fueron y los que no.
8. (Opcional) An√°lisis de correlaci√≥n
Usa data.corr() y un heatmap para ver correlaciones entre variables num√©ricas y el churn.
9. Informe final
Estructura tu notebook/script con:
Introducci√≥n
Limpieza y tratamiento
An√°lisis exploratorio (con visualizaciones)
Conclusiones e insights
Recomendaciones
'''
